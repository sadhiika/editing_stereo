<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Further Reading - StereoWipe</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/research.css') }}">
</head>
<body>
    <nav>
        <ul>
            <li><strong>StereoWipe</strong></li>
            <li><a href="/">Home</a></li>
            <li><a href="/documentation">Documentation</a></li>
            <li><a href="/about">About</a></li>
            <li><a href="/resources">Resources</a></li>
            <li><a href="/faq">FAQ</a></li>
            <li><a href="/arena">Arena</a></li>
            <li><a href="/leaderboard">Leaderboard</a></li>
            <li><a href="/annotate">Annotate</a></li>
        </ul>
    </nav>

    <main>
        <h1>Further Reading</h1>
        
        <section class="section">
            <h2>Benchmark Datasets for Stereotype Testing</h2>
            <ul>
                <li>
                    <a href="https://aclanthology.org/2021.acl-long.416.pdf">StereoSet Paper</a>
                    <div class="citation">Standard for LM stereotype scoring across gender, profession, race & religion</div>
                </li>
                <li>
                    <a href="https://aclanthology.org/2020.emnlp-main.154/">CrowS-Pairs Dataset</a>
                    <div class="citation">Preference-based bias measurement with 1,508 doublets across 9 bias types</div>
                </li>
                <li>
                    <a href="https://github.com/amazon-science/bold">BOLD Prompts</a>
                    <div class="citation">Toxicity & sentiment drift in open-ended generation with 23,679 prompts</div>
                </li>
                <li>
                    <a href="https://huggingface.co/datasets/allenai/real-toxicity-prompts">RealToxicityPrompts</a>
                    <div class="citation">100k prompts for testing toxicity propensity in web snippet completions</div>
                </li>
                <li>
                    <a href="https://aclanthology.org/2023.emnlp-main.874.pdf">Multilingual Holistic Bias Paper</a>
                    <div class="citation">460k English templates expanded to 20k+ sentences in 50 languages</div>
                </li>
            </ul>
        </section>

        <section class="section">
            <h2>Holistic Evaluation Frameworks</h2>
            <ul>
                <li>
                    <a href="https://crfm.stanford.edu/helm/">HELM Benchmark</a>
                    <div class="citation">Multi-metric leaderboard with accuracy, calibration, bias, toxicity, and cost metrics</div>
                </li>
                <li>
                    <a href="https://mlcommons.org/2023/10/mlcommons-announces-the-formation-of-ai-safety-working-group/">MLCommons AI-Safety Working Group</a>
                    <div class="citation">Community test pool for standardized bias evaluation tasks</div>
                </li>
                <li>
                    <a href="https://github.com/tensorflow/fairness-indicators">TensorFlow Fairness Indicators</a>
                    <div class="citation">Compute parity metrics per slice with CI pipeline integration</div>
                </li>
                <li>
                    <a href="https://ai.meta.com/blog/how-were-using-fairness-flow-to-help-build-ai-that-works-better-for-everyone/">Meta Fairness Flow</a>
                    <div class="citation">Slice-based visualizations for CV and language models</div>
                </li>
                <li>
                    <a href="https://about.fb.com/news/2023/03/more-inclusive-dataset-to-measure-fairness-in-ai/">Casual Conversations v2 Dataset</a>
                    <div class="citation">High-resolution ground-truth labels for skin-tone & age</div>
                </li>
            </ul>
        </section>

        <section class="section">
            <h2>Red-Teaming & Incident Tracking</h2>
            <ul>
                <li>
                    <a href="https://cdn.openai.com/papers/openais-approach-to-external-red-teaming.pdf">OpenAI External Red-Teaming Paper</a>
                    <div class="citation">Structured playbook defining roles, threat taxonomies, and reporting formats</div>
                </li>
                <li>
                    <a href="https://incidentdatabase.ai/">AI Incident Database</a>
                    <div class="citation">Repository of real-world AI harms and near-misses</div>
                </li>
                <li>
                    <a href="https://addons.mozilla.org/en-US/firefox/addon/regretsreporter/">Mozilla RegretsReporter</a>
                    <div class="citation">Browser extension for flagging toxic content recommendations</div>
                </li>
            </ul>
        </section>

        <section class="section">
            <h2>Civil Society & Advocacy Resources</h2>
            <ul>
                <li>
                    <a href="https://algorithmwatch.org/en/how-and-why-algorithms-discriminate/">AlgorithmWatch Explainer</a>
                    <div class="citation">Case studies and legal analysis of algorithmic discrimination</div>
                </li>
                <li>
                    <a href="https://www.ajl.org/">Algorithmic Justice League</a>
                    <div class="citation">Public campaigns & participatory audits for AI accountability</div>
                </li>
                <li>
                    <a href="https://rankingdigitalrights.org/">Ranking Digital Rights</a>
                    <div class="citation">Corporate Accountability Index for transparency and human rights</div>
                </li>
                <li>
                    <a href="https://ainowinstitute.org/wp-content/uploads/2023/04/AI-Now-2023-Landscape-Report-FINAL.pdf">AI Now 2023 Landscape Report</a>
                    <div class="citation">Annual report linking technical bias to governance gaps</div>
                </li>
                <li>
                    <a href="https://www.ai4d.ai/research">AI4D Research Directory</a>
                    <div class="citation">Locally-led research and policy prototypes countering data colonialism</div>
                </li>
            </ul>
        </section>

        <section class="section">
            <h2>Global South & Data Colonialism Research</h2>
            <ul>
                <li>
                    <a href="https://www.weforum.org/stories/2023/01/davos23-ai-divide-global-north-global-south/">WEF AI-Divide Article</a>
                    <div class="citation">Analysis of AI-driven GDP gaps between North and South</div>
                </li>
                <li>
                    <a href="https://www.wired.com/story/abeba-birhane-ai-datasets/">Wired on Dataset Colonialism</a>
                    <div class="citation">Geographic and linguistic biases in training data</div>
                </li>
            </ul>
        </section>
    </main>

    <footer>
        <p>StereoWipe Benchmark | <a href="https://github.com/stereowipe">GitHub</a> | <a href="/volunteer">Volunteer Researchers</a> | <a href="/further_reading">Further Reading</a></p>
    </footer>
</body>
</html>